# ğŸ§ª Usability Testing Guide - ConfiterÃ­a Quelita

**VersiÃ³n:** 1.0.0
**Ãšltima actualizaciÃ³n:** 3 de Diciembre, 2025
**Objetivo:** Validar la experiencia de usuario antes del deploy a producciÃ³n

---

## ğŸ“‹ Tabla de Contenidos

1. [IntroducciÃ³n](#introducciÃ³n)
2. [Objetivos del Testing](#objetivos-del-testing)
3. [PreparaciÃ³n](#preparaciÃ³n)
4. [Reclutamiento de Participantes](#reclutamiento-de-participantes)
5. [Tareas de Prueba](#tareas-de-prueba)
6. [Protocolo de Testing](#protocolo-de-testing)
7. [MÃ©tricas y Observables](#mÃ©tricas-y-observables)
8. [Template de Reporte](#template-de-reporte)
9. [AnÃ¡lisis y PriorizaciÃ³n](#anÃ¡lisis-y-priorizaciÃ³n)
10. [Checklist Pre-Deploy](#checklist-pre-deploy)

---

## ğŸ¯ IntroducciÃ³n

Esta guÃ­a te ayudarÃ¡ a realizar **tests de usabilidad** con usuarios reales para identificar problemas y oportunidades de mejora antes del lanzamiento en producciÃ³n.

### Â¿Por quÃ© Testing de Usabilidad?

- âœ… **Detectar problemas** antes que los usuarios reales
- âœ… **Validar decisiones de diseÃ±o** con feedback real
- âœ… **Mejorar conversiÃ³n** al eliminar fricciones
- âœ… **Reducir costos** de soporte post-lanzamiento

### Recursos Necesarios

- **Tiempo:** 6 horas totales (2h prep + 3h tests + 1h anÃ¡lisis)
- **Participantes:** 3-5 usuarios
- **Equipo:** 1 moderador (tÃº) + 1 observador opcional
- **Herramientas:** GrabaciÃ³n de pantalla, notas, dispositivos mÃ³viles

---

## ğŸ¯ Objetivos del Testing

### Objetivos Principales

1. **Validar flujo de compra completo**
   - Â¿Los usuarios pueden encontrar y comprar productos?
   - Â¿El checkout es claro y sin fricciones?

2. **Evaluar navegaciÃ³n y arquitectura de informaciÃ³n**
   - Â¿Los usuarios encuentran lo que buscan?
   - Â¿Los filtros son intuitivos?

3. **Medir percepciÃ³n de marca y calidad**
   - Â¿La UI se siente premium?
   - Â¿Genera confianza para comprar?

4. **Identificar problemas tÃ©cnicos**
   - Â¿Hay bugs o errores?
   - Â¿La performance es aceptable?

### MÃ©tricas de Ã‰xito

- **Task Success Rate:** >80% (4 de 5 tareas completadas)
- **Time on Task:** <2 minutos por tarea
- **Error Rate:** <10% (menos de 1 error cada 10 interacciones)
- **Satisfaction Score:** >4/5 en escala Likert

---

## ğŸ› ï¸ PreparaciÃ³n (2 horas)

### Paso 1: Configurar Entorno de Testing

```bash
# 1. Levantar el proyecto en local
cd frontend
npm run dev

# 2. Verificar que todo funciona
# - Productos cargando correctamente
# - Carrito funcional
# - Checkout simulado (sin pagar realmente)
# - Admin accesible con credenciales de prueba
```

**URLs a probar:**
- Home: http://localhost:3000
- Productos: http://localhost:3000/productos
- Producto individual: http://localhost:3000/productos/[slug]
- Carrito: Click en Ã­cono del carrito
- Checkout: http://localhost:3000/checkout
- Admin: http://localhost:3000/admin (opcional)

### Paso 2: Preparar Datos de Prueba

**Crear productos de prueba:**
- âœ… Al menos 20 productos visibles
- âœ… Con imÃ¡genes reales
- âœ… Con variantes (tamaÃ±os, sabores)
- âœ… Con descuentos activos
- âœ… Con stock disponible

**Credenciales de prueba:**
```
Usuario Cliente:
Email: test@quelita.com
Password: Test1234!

Usuario Admin (opcional):
Email: admin@quelita.com
Password: Admin1234!
```

### Paso 3: Preparar Herramientas de GrabaciÃ³n

**OpciÃ³n A: Windows** (Recomendado)
- Windows Game Bar: `Win + G` â†’ Grabar
- OBS Studio: https://obsproject.com/ (gratuito)

**OpciÃ³n B: Mac**
- QuickTime: File â†’ New Screen Recording

**OpciÃ³n C: Online**
- Loom (gratuito 5 min): https://loom.com
- Zoom (con screen share)

### Paso 4: Preparar Scripts y Materiales

Imprimir o tener en pantalla:
- [ ] Script de introducciÃ³n
- [ ] Lista de tareas
- [ ] Cuestionario post-test
- [ ] Hoja de observaciones

---

## ğŸ‘¥ Reclutamiento de Participantes

### Perfil Ideal (3-5 usuarios)

**SegmentaciÃ³n:**
- **2 usuarios:** Target principal (mujeres/hombres 25-45 que compran dulces)
- **1 usuario:** Usuario senior (50+) para accesibilidad
- **1 usuario:** Usuario joven (18-24) nativos digitales
- **1 usuario:** Usuario mÃ³vil-first (usa smartphone principalmente)

**Criterios de exclusiÃ³n:**
- âŒ Desarrolladores web (muy tÃ©cnicos)
- âŒ Familiares directos (bias)
- âŒ Personas que conocen el proyecto

**DÃ³nde reclutar:**
- Amigos de amigos
- Grupos de Facebook locales
- CompaÃ±eros de trabajo
- Clientes actuales del negocio (si aplica)

### Incentivos (Opcional)

- $5-10 USD en crÃ©dito para la tienda
- Descuento del 20% en primera compra
- Producto gratis pequeÃ±o

---

## ğŸ“ Tareas de Prueba

### Tarea 1: ExploraciÃ³n Inicial (5 min)

**Objetivo:** Evaluar primera impresiÃ³n y navegaciÃ³n libre

**Script:**
> "Imagina que acabas de descubrir esta tienda de dulces online. Explora libremente durante 2 minutos y cuÃ©ntame en voz alta quÃ© llama tu atenciÃ³n y quÃ© piensas."

**Observables:**
- âœ“ Â¿DÃ³nde mira primero?
- âœ“ Â¿Hace scroll inmediatamente?
- âœ“ Â¿Comenta sobre diseÃ±o/colores?
- âœ“ Â¿Hace click en productos?

**Preguntas post-tarea:**
- "Â¿QuÃ© opinas de la apariencia general?"
- "Â¿ConfiarÃ­as en comprar aquÃ­?"
- "Â¿Algo te confunde o te parece raro?"

---

### Tarea 2: Buscar Producto EspecÃ­fico (3 min)

**Objetivo:** Evaluar bÃºsqueda y filtros

**Script:**
> "Quieres comprar **chocolates** para regalar. Encuentra algÃºn producto de chocolate que te guste."

**Observables:**
- âœ“ Â¿Usa el buscador o navega por categorÃ­as?
- âœ“ Â¿Encuentra los filtros?
- âœ“ Â¿Los filtros son claros?
- âœ“ Â¿Tiempo para encontrar un producto?

**Variaciones:**
- "Encuentra un producto en **oferta**"
- "Encuentra productos de la marca **X**"
- "Filtra por precio de menor a mayor"

**MÃ©tricas:**
- â±ï¸ Tiempo: <1 minuto (Ã©xito), 1-2 min (aceptable), >2 min (problema)
- âœ… Success Rate: >80%

---

### Tarea 3: Agregar al Carrito (2 min)

**Objetivo:** Evaluar flujo de add-to-cart

**Script:**
> "Agrega al carrito **2 unidades** de este producto que acabas de encontrar."

**Observables:**
- âœ“ Â¿Encuentra el botÃ³n de agregar?
- âœ“ Â¿Nota la animaciÃ³n de confetti?
- âœ“ Â¿Cambia la cantidad antes o despuÃ©s de agregar?
- âœ“ Â¿Ve el badge del carrito actualizÃ¡ndose?
- âœ“ Â¿Comenta sobre las animaciones?

**Preguntas post-tarea:**
- "Â¿Notaste algÃºn cambio visual al agregar?"
- "Â¿Fue claro que el producto se agregÃ³?"
- "Â¿La experiencia te resultÃ³ agradable o molesta?"

---

### Tarea 4: Revisar y Modificar Carrito (3 min)

**Objetivo:** Evaluar carrito y gestiÃ³n de productos

**Script:**
> "Ahora revisa tu carrito de compras. Cambia la cantidad de uno de los productos y elimina otro."

**Observables:**
- âœ“ Â¿Encuentra cÃ³mo abrir el carrito?
- âœ“ Â¿Los controles de cantidad son claros?
- âœ“ Â¿Encuentra el botÃ³n de eliminar?
- âœ“ Â¿Nota las animaciones del cart drawer?
- âœ“ Â¿Revisa el total antes de continuar?

**Preguntas post-tarea:**
- "Â¿Fue fÃ¡cil modificar las cantidades?"
- "Â¿El total se actualiza claramente?"
- "Â¿Algo te confundiÃ³ en el carrito?"

---

### Tarea 5: Completar Checkout (5 min)

**Objetivo:** Evaluar flujo de pago (sin pagar realmente)

**Script:**
> "Procede al checkout como si fueras a comprar. **NO** completes el pago real, solo llena los formularios hasta el final."

**Observables:**
- âœ“ Â¿Los campos del formulario son claros?
- âœ“ Â¿La validaciÃ³n es Ãºtil o molesta?
- âœ“ Â¿ConfÃ­a en ingresar datos de pago?
- âœ“ Â¿Lee el resumen del pedido?
- âœ“ Â¿Le preocupa algo antes de "pagar"?

**Formularios a evaluar:**
- Datos personales (nombre, email, telÃ©fono)
- DirecciÃ³n de envÃ­o
- MÃ©todo de pago (visual)
- Resumen del pedido

**MÃ©tricas:**
- â±ï¸ Tiempo: <3 minutos (Ã©xito)
- âŒ Errores de validaciÃ³n: <2
- âœ… Success Rate: >75%

---

### Tarea 6: Testing MÃ³vil (5 min)

**Objetivo:** Evaluar experiencia en smartphone

**Script:**
> "Ahora vamos a probar en tu telÃ©fono. Repite las mismas tareas: busca un producto, agrÃ©galo al carrito, y revisa el checkout."

**Dispositivos a probar:**
- iOS (iPhone)
- Android (Samsung, Xiaomi, etc.)
- Tablet (opcional)

**Observables especÃ­ficos mÃ³vil:**
- âœ“ Â¿Botones suficientemente grandes? (touch targets >44px)
- âœ“ Â¿Scroll fluido?
- âœ“ Â¿Modales/drawers funcionan bien?
- âœ“ Â¿Teclado no tapa campos importantes?
- âœ“ Â¿ImÃ¡genes cargan rÃ¡pido?

---

## ğŸ“‹ Protocolo de Testing

### Pre-Test (5 min por participante)

**1. Bienvenida y Contexto**

> "Hola [nombre], gracias por ayudarme. Voy a mostrarte un sitio web de una confiterÃ­a online y me gustarÃ­a que lo pruebes como si fueras a comprar. No hay respuestas correctas o incorrectas - lo que quiero es ver cÃ³mo interactÃºas naturalmente con el sitio."

**2. Consentimiento**

> "Voy a grabar la pantalla para revisar despuÃ©s. Â¿EstÃ¡s de acuerdo? Tus datos serÃ¡n anÃ³nimos y solo usarÃ© esta informaciÃ³n para mejorar el sitio."

**3. Instrucciones**

> "Por favor, **piensa en voz alta** mientras navegas. Dime quÃ© estÃ¡s mirando, quÃ© piensas hacer, y cualquier duda o confusiÃ³n que tengas. No te preocupes por ofenderme - cualquier crÃ­tica es sÃºper valiosa."

### Durante el Test (30-40 min por participante)

**TÃ©cnicas de moderaciÃ³n:**

âœ… **HACER:**
- Escuchar activamente sin interrumpir
- Tomar notas de observaciones
- Hacer preguntas abiertas: "Â¿QuÃ© piensas de esto?"
- Dejar silencios cÃ³modos (no llenar cada pausa)
- Preguntar "por quÃ©" para entender razonamiento

âŒ **NO HACER:**
- Dar pistas o ayudar ("haz click ahÃ­")
- Defender decisiones de diseÃ±o
- Interrumpir el flujo del usuario
- Hacer preguntas leading: "Â¿No crees que esto es claro?"

**Si el usuario se atasca:**

> "Â¿QuÃ© esperarÃ­as que pasara ahora?"
> "Â¿DÃ³nde buscarÃ­as esa funciÃ³n?"
> "Si esto fuera tu sitio favorito, Â¿cÃ³mo funcionarÃ­a?"

### Post-Test (10 min por participante)

**Cuestionario de SatisfacciÃ³n:**

1. **Apariencia General** (1-5)
   - "Â¿CÃ³mo calificarÃ­as el diseÃ±o visual del sitio?"

2. **Facilidad de Uso** (1-5)
   - "Â¿QuÃ© tan fÃ¡cil fue encontrar y comprar productos?"

3. **Confianza** (1-5)
   - "Â¿QuÃ© tan cÃ³modo te sentirÃ­as comprando aquÃ­ con tu tarjeta?"

4. **Velocidad** (1-5)
   - "Â¿El sitio te pareciÃ³ rÃ¡pido o lento?"

5. **RecomendaciÃ³n** (1-5)
   - "Â¿RecomendarÃ­as este sitio a un amigo?"

**Preguntas Abiertas:**

1. "Â¿QuÃ© fue lo que MÃS te gustÃ³ del sitio?"
2. "Â¿QuÃ© fue lo que MENOS te gustÃ³ o te frustrÃ³?"
3. "Â¿Algo te confundiÃ³ o no sabÃ­as cÃ³mo usar?"
4. "Si pudieras cambiar UNA cosa, Â¿quÃ© serÃ­a?"
5. "Â¿Hay algo que esperabas encontrar pero no viste?"

---

## ğŸ“Š MÃ©tricas y Observables

### MÃ©tricas Cuantitativas

| MÃ©trica | Objetivo | CÃ³mo Medir |
|---------|----------|------------|
| **Task Success Rate** | >80% | Tareas completadas / Total tareas |
| **Time on Task** | <2 min/tarea | CronÃ³metro por tarea |
| **Error Rate** | <10% | Clicks errÃ³neos / Total clicks |
| **Satisfaction Score** | >4/5 | Promedio del cuestionario |

### MÃ©tricas Cualitativas

**Nivel de FrustraciÃ³n:**
- ğŸ˜Š **Bajo:** Usuario sonrÃ­e, comenta positivamente
- ğŸ˜ **Medio:** Pausas, dudas, "mmm..."
- ğŸ˜¤ **Alto:** Suspiros, quejas, "Â¿dÃ³nde estÃ¡?"

**Comentarios EspontÃ¡neos:**
- ğŸ’¬ Positivos: "Me gusta", "EstÃ¡ bonito", "QuÃ© bueno"
- ğŸ’¬ Negativos: "No entiendo", "Esto es raro", "Esperaba..."
- ğŸ’¬ Sugerencias: "SerÃ­a mejor si...", "DeberÃ­a..."

### Template de ObservaciÃ³n

```markdown
## SesiÃ³n #[X] - [Fecha]

**Participante:** [Nombre/Alias]
**Perfil:** [Edad, ocupaciÃ³n, nivel tÃ©cnico]
**Dispositivo:** [Desktop/MÃ³vil, SO, navegador]
**DuraciÃ³n:** [XX min]

### Tarea 1: ExploraciÃ³n Inicial
- â±ï¸ Tiempo: XX:XX
- âœ…/âŒ Completada: SÃ­/No
- ğŸ’¬ Comentarios: "..."
- ğŸ› Problemas: ...

### Tarea 2: Buscar Producto
- â±ï¸ Tiempo: XX:XX
- âœ…/âŒ Completada: SÃ­/No
- ğŸ’¬ Comentarios: "..."
- ğŸ› Problemas: ...

[...resto de tareas]

### Observaciones Generales
- Nivel de frustraciÃ³n: Bajo/Medio/Alto
- Comentarios destacados: ...
- Bugs encontrados: ...

### Scores Post-Test
- Apariencia: [1-5]
- Facilidad: [1-5]
- Confianza: [1-5]
- Velocidad: [1-5]
- RecomendaciÃ³n: [1-5]

**Promedio:** X.X/5
```

---

## ğŸ“ˆ AnÃ¡lisis y PriorizaciÃ³n

### Paso 1: Consolidar Findings (1 hora)

DespuÃ©s de las 3-5 sesiones, agrupa los problemas encontrados:

**Ejemplo de consolidaciÃ³n:**

```markdown
## Problemas Encontrados

### Problema #1: Filtros no se ven en mÃ³vil
- **Severidad:** Alta
- **Frecuencia:** 4/5 usuarios
- **Impacto:** No pueden filtrar productos en mÃ³vil
- **Evidencia:** "No encuentro cÃ³mo filtrar por precio"

### Problema #2: Badge de descuento poco visible
- **Severidad:** Media
- **Frecuencia:** 3/5 usuarios
- **Impacto:** No notan las ofertas
- **Evidencia:** "No vi que habÃ­a descuento"

### Problema #3: ConfusiÃ³n en variantes
- **Severidad:** Media
- **Frecuencia:** 2/5 usuarios
- **Impacto:** Agregan producto equivocado
- **Evidencia:** "PensÃ© que era tamaÃ±o grande"
```

### Paso 2: Matriz de PriorizaciÃ³n

| Problema | Severidad | Frecuencia | Esfuerzo | Prioridad |
|----------|-----------|------------|----------|-----------|
| Filtros mÃ³vil | Alta | 4/5 | 4h | ğŸ”´ CRÃTICO |
| Badge descuento | Media | 3/5 | 1h | ğŸŸ¡ MEDIO |
| Variantes | Media | 2/5 | 2h | ğŸŸ¢ BAJO |

**FÃ³rmula de prioridad:**
```
Prioridad = (Severidad Ã— Frecuencia) / Esfuerzo

Severidad: 1 (baja), 2 (media), 3 (alta), 4 (crÃ­tica)
Frecuencia: 1-5 (nÃºmero de usuarios)
Esfuerzo: 1 (< 2h), 2 (2-4h), 3 (4-8h), 4 (>8h)
```

### Paso 3: Plan de AcciÃ³n

**Problemas CrÃ­ticos (Fix antes del deploy):**
- [ ] Problema con frecuencia >3/5 usuarios
- [ ] Severidad alta que bloquea tareas
- [ ] Bugs que rompen funcionalidad

**Problemas Importantes (Fix en iteraciÃ³n 1 post-launch):**
- [ ] Frecuencia 2-3/5 usuarios
- [ ] Severidad media
- [ ] UX improvements

**Nice-to-Have (Backlog):**
- [ ] Frecuencia <2/5 usuarios
- [ ] Severidad baja
- [ ] Sugerencias de features nuevas

---

## âœ… Checklist Pre-Deploy

### Tests Funcionales

- [ ] âœ… Flujo de compra completo funciona (inicio a fin)
- [ ] âœ… Carrito persiste en refresh
- [ ] âœ… Filtros funcionan correctamente
- [ ] âœ… BÃºsqueda devuelve resultados relevantes
- [ ] âœ… ImÃ¡genes cargan correctamente
- [ ] âœ… Formularios validan campos
- [ ] âœ… Animaciones no causan bugs

### Tests de Compatibilidad

**Navegadores:**
- [ ] Chrome (Ãºltima versiÃ³n)
- [ ] Firefox (Ãºltima versiÃ³n)
- [ ] Safari (Mac/iOS)
- [ ] Edge (Ãºltima versiÃ³n)

**Dispositivos:**
- [ ] Desktop 1920x1080
- [ ] Laptop 1366x768
- [ ] Tablet 768px
- [ ] MÃ³vil 375px (iPhone SE)
- [ ] MÃ³vil 414px (iPhone Plus)

### Tests de Performance

- [ ] Lighthouse Score >85 en Performance
- [ ] LCP <3s
- [ ] FID <100ms
- [ ] CLS <0.1
- [ ] Sin errores de consola en producciÃ³n

### Tests de Accesibilidad

- [ ] NavegaciÃ³n por teclado funciona (Tab, Enter, Esc)
- [ ] Screen reader compatible (probar con NVDA/JAWS)
- [ ] Contraste de colores WCAG AA
- [ ] Focus states visibles
- [ ] Alt text en todas las imÃ¡genes

### Tests de SEO

- [ ] Meta tags presentes en todas las pÃ¡ginas
- [ ] Open Graph tags configurados
- [ ] robots.txt accesible
- [ ] sitemap.xml generado
- [ ] URLs amigables (sin parÃ¡metros raros)

---

## ğŸ“„ Template de Reporte Final

```markdown
# Reporte de Usability Testing - ConfiterÃ­a Quelita

**Fecha:** [DD/MM/YYYY]
**Moderador:** [Tu nombre]
**Participantes:** 5 usuarios

---

## ğŸ“Š Resumen Ejecutivo

- **Task Success Rate:** XX% (objetivo: >80%)
- **Satisfaction Score:** X.X/5 (objetivo: >4/5)
- **Problemas CrÃ­ticos Encontrados:** X
- **Problemas Importantes:** X
- **Sugerencias de Mejora:** X

**RecomendaciÃ³n:** âœ… Listo para deploy / âš ï¸ Fixes menores / âŒ Requiere trabajo

---

## ğŸ¯ Findings Principales

### 1. [TÃ­tulo del problema]
- **Severidad:** Alta/Media/Baja
- **Frecuencia:** X/5 usuarios
- **DescripciÃ³n:** ...
- **Evidencia:** "Quote del usuario"
- **RecomendaciÃ³n:** ...

### 2. [TÃ­tulo del problema]
...

---

## ğŸ’¡ Insights Positivos

- âœ… "El diseÃ±o es muy bonito y profesional" (5/5 usuarios)
- âœ… "Las animaciones son agradables, no molestas" (4/5 usuarios)
- âœ… "El carrito es muy claro" (4/5 usuarios)

---

## ğŸ”§ Plan de AcciÃ³n

### Pre-Deploy (CrÃ­tico)
- [ ] Fix problema #1
- [ ] Fix problema #2

### Post-Deploy IteraciÃ³n 1 (2 semanas)
- [ ] Mejora #1
- [ ] Mejora #2

### Backlog (Futuro)
- [ ] Feature #1
- [ ] Feature #2

---

## ğŸ“ Anexos

- Grabaciones de sesiones: [Link]
- Hoja de observaciones: [Link]
- Cuestionarios completados: [Link]
```

---

## ğŸ“ Tips Finales

### Antes del Test

1. **Practica con un colega** primero (dry run)
2. **Prepara backup** (si falla el servidor, tener capturas)
3. **Ten agua/cafÃ©** para los participantes
4. **Configura "No molestar"** en tu computadora

### Durante el Test

1. **No te pongas defensivo** ante crÃ­ticas
2. **Deja que se equivoquen** (es informaciÃ³n valiosa)
3. **Graba todo** (pantalla + audio)
4. **Toma notas de timestamps** para revisar despuÃ©s

### DespuÃ©s del Test

1. **Revisa grabaciones mismo dÃ­a** (mientras estÃ¡ fresco)
2. **Agradece a participantes** con email de seguimiento
3. **Comparte findings** con el equipo rÃ¡pido
4. **Prioriza fixes** antes que agregues features nuevas

---

**Â¡Ã‰xito con tus tests!** ğŸš€

Recuerda: **5 usuarios encuentran el 85% de los problemas de usabilidad**. No necesitas 50 personas, 3-5 usuarios bien seleccionados son suficientes para un MVP.

---

**Ãšltima actualizaciÃ³n:** 3 de Diciembre, 2025
**Autor:** Equipo ConfiterÃ­a Quelita
**VersiÃ³n:** 1.0.0
